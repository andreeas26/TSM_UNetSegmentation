{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrpBYYkbvyM3"
   },
   "source": [
    "## Preparing the setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFimYa-h5YQo"
   },
   "outputs": [],
   "source": [
    "#@title Mount drive content\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My\\ Drive/Work/TSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ul-6c886tZXZ"
   },
   "outputs": [],
   "source": [
    "import pathlib as pt\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
    "from keras import optimizers\n",
    "\n",
    "import generators as gen\n",
    "import custom_metrics as cm\n",
    "from UNetModel import UNetModel\n",
    "\n",
    "print(\"Keras\", keras.__version__)\n",
    "print(\"Tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTavlWZufKob"
   },
   "source": [
    "### Set useful paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nzITfVSvck9t"
   },
   "outputs": [],
   "source": [
    "RUN_TIME = datetime.now().strftime(\"%Y_%m_%d-%H_%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-ex9OzutZfd"
   },
   "outputs": [],
   "source": [
    "# paths for the data\n",
    "ROOT_PATH    = pt.Path(\"/content/drive/My Drive/Work/TSM\")\n",
    "DATASET_PATH = ROOT_PATH/\"dataset\"\n",
    "IMGS_DIR     = \"images\"\n",
    "MASKS_DIR    = \"masks\"\n",
    "CONFIG_PATH  = ROOT_PATH/\"config_train.yaml\"\n",
    "IMGS_CSV     = DATASET_PATH/\"images.csv\"\n",
    "MASKS_CSV    = DATASET_PATH/\"masks.csv\"\n",
    "\n",
    "# paths for callbacks\n",
    "TRAIN_PATH       = ROOT_PATH/\"trainings\"/RUN_TIME\n",
    "CHECKPOINTS_PATH = TRAIN_PATH/\"checkpoints\"\n",
    "\n",
    "if not TRAIN_PATH.exists():\n",
    "  os.makedirs(str(TRAIN_PATH))\n",
    "\n",
    "if not CHECKPOINTS_PATH.exists():\n",
    "  os.mkdir(str(CHECKPOINTS_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16lvxQVAv70z"
   },
   "source": [
    "## Training U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfPkBvfrtZiA"
   },
   "outputs": [],
   "source": [
    "with open(CONFIG_PATH) as fp:\n",
    "  config = yaml.safe_load(fp)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "16MPVLOAAz4X"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mppVhjRA1zb"
   },
   "outputs": [],
   "source": [
    "imgs_df  = pd.read_csv(IMGS_CSV)\n",
    "masks_df = pd.read_csv(MASKS_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF94iB0ngvfB"
   },
   "source": [
    "#### Create 2 csvs with file paths for images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "drWr8eootZkg"
   },
   "outputs": [],
   "source": [
    "# img_paths = sorted(list((DATASET_PATH/IMGS_DIR).glob(\"*\")), key=lambda p: p.stem)\n",
    "# mask_paths = sorted(list((DATASET_PATH/MASKS_DIR).glob(\"*\")), key=lambda p: p.stem)\n",
    "# print(\"[INFO] Found {} images and {} masks\".format(len(img_paths), len(mask_paths)))\n",
    "\n",
    "# imgs_df = pd.DataFrame(data={'file_path': img_paths})\n",
    "# masks_df = pd.DataFrame(data={'file_path': mask_paths})\n",
    "\n",
    "# imgs_df[\"tumor_type\"]  = [\"MASS\" if \"MASS\" in str(p) else \"CALC\" for p in imgs_df[\"file_path\"]]\n",
    "# masks_df[\"tumor_type\"] = [\"MASS\" if \"MASS\" in str(p) else \"CALC\" for p in masks_df[\"file_path\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOM0qvJ2EQ5E"
   },
   "source": [
    "#### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uo5GanditZpJ"
   },
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# np.random.seed(seed)\n",
    "# total = len(imgs_df)\n",
    "# indices = np.arange(0, total)\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "# imgs_df['subset'] = ''\n",
    "# masks_df['subset'] = ''\n",
    "\n",
    "# start_idx = 0\n",
    "# for _subset in config['dataset']:\n",
    "#   print(_subset, config['dataset'][_subset])\n",
    "#   next_idx = int(config['dataset'][_subset] * total)\n",
    "#   print(next_idx)\n",
    "#   selected = indices[start_idx:next_idx]\n",
    "#   imgs_df.loc[imgs_df.index.isin(selected), 'subset'] = _subset\n",
    "#   masks_df.loc[masks_df.index.isin(selected), 'subset'] = _subset\n",
    "#   start_idx = next_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RbhmNEd1H4EM"
   },
   "outputs": [],
   "source": [
    "# imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt7j8Q_rtZm3"
   },
   "outputs": [],
   "source": [
    "# imgs_df.to_csv(IMGS_CSV, index=False)\n",
    "# masks_df.to_csv(MASKS_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YKqulbBCNrVP"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1xu-VRn4X5mP"
   },
   "source": [
    "#### Build the U-Net model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmKTXClytZzI"
   },
   "outputs": [],
   "source": [
    "unet = UNetModel()\n",
    "model = unet.build(width=config['target_size'][0],\n",
    "                  height=config['target_size'][1],\n",
    "                  n_channels=config['n_channels'],\n",
    "                  with_bn=True)\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wEnuKhDgYv6n"
   },
   "outputs": [],
   "source": [
    "def choose_optimizer(opt_name, opt_param):\n",
    "    if opt_name == 'rmsprop':\n",
    "        return optimizers.RMSprop(**opt_param)\n",
    "    elif opt_name == 'adam':\n",
    "        return optimizers.Adam(**opt_param)\n",
    "    elif opt_name == 'sgd':\n",
    "        return optimizers.SGD(**opt_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9iQU_3w3tZ1n"
   },
   "outputs": [],
   "source": [
    "opt = choose_optimizer(config['opt_name'], config['opt_param'])\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZ2AC9titZ3s"
   },
   "outputs": [],
   "source": [
    " model.compile(optimizer=opt, loss=cm.dice_coef_loss, metrics=[cm.dice_coef])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "skqgsNddZe4t"
   },
   "source": [
    "#### Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Hp3--e4ZuXy"
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "file_path = CHECKPOINTS_PATH/\"unet_weights-{epoch:002d}-{val_loss:.5f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks.append(checkpoint)\n",
    "\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=config[\"patience\"])\n",
    "# callbacks.append(early_stopping)\n",
    "\n",
    "csv_filename = TRAIN_PATH/\"history_{}.csv\".format(RUN_TIME)\n",
    "csv_logger = CSVLogger(csv_filename, separator=',', append=True)\n",
    "callbacks.append(csv_logger)\n",
    "print(\"[INFO] Added {} callbacks\".format(len(callbacks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HSmwv2bdeonj"
   },
   "source": [
    "#### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IUyFeZTwtZwn"
   },
   "outputs": [],
   "source": [
    "image_shape = [config['batch_size'], config['target_size'][0], config['target_size'][1], config['n_channels']]\n",
    "mask_shape  = [config['batch_size'], config['target_size'][0], config['target_size'][1], 1]\n",
    "seed = 43\n",
    "\n",
    "train_generator = gen.image_mask_generator_imgaug(imgs_df,\n",
    "                                                  masks_df,\n",
    "                                                  subset=\"train\",\n",
    "                                                  batch_size=config['batch_size'],\n",
    "                                                  target_size=config['target_size'],\n",
    "                                                  data_aug=True,\n",
    "                                                  seed=seed)\n",
    "\n",
    "val_generator = gen.image_mask_generator_imgaug(imgs_df,\n",
    "                                                masks_df,\n",
    "                                                subset=\"val\",\n",
    "                                                batch_size=config['batch_size'],\n",
    "                                                target_size=config['target_size'],\n",
    "                                                data_aug=False,\n",
    "                                                seed=seed)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: map(tuple, train_generator), \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=(image_shape, mask_shape))\n",
    "print(\"[INFO] Train dataset: \", train_dataset)\n",
    "\n",
    "val_dataset   = tf.data.Dataset.from_generator(lambda: map(tuple, val_generator), \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=(image_shape, mask_shape))\n",
    "print(\"[INFO] Validation dataset: \", val_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wrAReJ0oSoTq"
   },
   "source": [
    "#### Vizualize a few training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCz1fUGUa722"
   },
   "outputs": [],
   "source": [
    "samples = list(train_dataset.take(4).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y4O_Y50Oblgn"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(samples), 2, figsize=(10, 7))\n",
    "idx_img = 0 # image & mask index from each batch\n",
    "for idx, _sample in enumerate(samples):\n",
    "  batch_img, batch_mask = _sample\n",
    "  print(batch_img.shape, batch_mask.shape)\n",
    "  ax[idx][0].imshow(batch_img[idx_img])\n",
    "  ax[idx][0].axis('off')\n",
    "\n",
    "  mask_shape = batch_mask[idx_img].shape[:2]\n",
    "  conv_mask = np.zeros(shape=(mask_shape[0], mask_shape[1], 3), dtype=np.float32)\n",
    "  conv_mask[:, :, 0] = batch_mask[idx_img][:, :, 0]\n",
    "  conv_mask[:, :, 1] = batch_mask[idx_img][:, :, 0]\n",
    "  conv_mask[:, :, 2] = batch_mask[idx_img][:, :, 0]\n",
    "\n",
    "  ax[idx][1].imshow(conv_mask)\n",
    "  ax[idx][1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k4WWRa-yZuiE"
   },
   "outputs": [],
   "source": [
    "train_nr_samples = len(imgs_df.loc[imgs_df['subset'] == \"train\", :])\n",
    "val_nr_samples   = len(imgs_df.loc[imgs_df['subset'] == \"val\", :])\n",
    "\n",
    "steps_per_epoch = np.ceil(train_nr_samples / config[\"batch_size\"])\n",
    "validation_steps = val_nr_samples // config[\"batch_size\"]\n",
    "\n",
    "print(\"[INFO] Train size {} Val size {}\".format(train_nr_samples, val_nr_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADMG0sDpZdf2"
   },
   "outputs": [],
   "source": [
    "print(\"[INFO] Starting training for {} epochs with batch size {}\".format(config['epochs'], config['batch_size']))\n",
    "model.fit(train_generator,\n",
    "          epochs=config[\"epochs\"],\n",
    "          validation_data=val_generator,\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          validation_steps=validation_steps,\n",
    "          verbose=1,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsXzxIXxZdkb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPw7EoLxNdK8ZvVYfvnuFW/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1pXs7tkihtfJjqc_7-mjIzU8pCMKkQd3H",
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
