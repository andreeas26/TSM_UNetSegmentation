{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1pXs7tkihtfJjqc_7-mjIzU8pCMKkQd3H",
      "authorship_tag": "ABX9TyPw7EoLxNdK8ZvVYfvnuFW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andreeas26/TSM_UNetSegmentation/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrpBYYkbvyM3",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFimYa-h5YQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Mount drive content\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/Work/TSM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ul-6c886tZXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib as pt\n",
        "import os\n",
        "import yaml\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping\n",
        "from keras import optimizers\n",
        "\n",
        "import generators as gen\n",
        "import custom_metrics as cm\n",
        "from UNetModel import UNetModel\n",
        "\n",
        "print(\"Keras\", keras.__version__)\n",
        "print(\"Tensorflow\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTavlWZufKob",
        "colab_type": "text"
      },
      "source": [
        "### Set useful paths\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzITfVSvck9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RUN_TIME = datetime.now().strftime(\"%Y_%m_%d-%H_%M\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-ex9OzutZfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# paths for the data\n",
        "ROOT_PATH    = pt.Path(\"/content/drive/My Drive/Work/TSM\")\n",
        "DATASET_PATH = ROOT_PATH/\"dataset\"\n",
        "IMGS_DIR     = \"images\"\n",
        "MASKS_DIR    = \"masks\"\n",
        "CONFIG_PATH  = ROOT_PATH/\"config_train.yaml\"\n",
        "IMGS_CSV     = DATASET_PATH/\"images.csv\"\n",
        "MASKS_CSV    = DATASET_PATH/\"masks.csv\"\n",
        "\n",
        "# paths for callbacks\n",
        "TRAIN_PATH       = ROOT_PATH/\"trainings\"/RUN_TIME\n",
        "CHECKPOINTS_PATH = TRAIN_PATH/\"checkpoints\"\n",
        "\n",
        "if not TRAIN_PATH.exists():\n",
        "  os.makedirs(str(TRAIN_PATH))\n",
        "\n",
        "if not CHECKPOINTS_PATH.exists():\n",
        "  os.mkdir(str(CHECKPOINTS_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lvxQVAv70z",
        "colab_type": "text"
      },
      "source": [
        "## Training U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfPkBvfrtZiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(CONFIG_PATH) as fp:\n",
        "  config = yaml.safe_load(fp)\n",
        "config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16MPVLOAAz4X",
        "colab_type": "text"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mppVhjRA1zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs_df  = pd.read_csv(IMGS_CSV)\n",
        "masks_df = pd.read_csv(MASKS_CSV)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF94iB0ngvfB",
        "colab_type": "text"
      },
      "source": [
        "#### Create 2 csvs with file paths for images and masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drWr8eootZkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# img_paths = sorted(list((DATASET_PATH/IMGS_DIR).glob(\"*\")), key=lambda p: p.stem)\n",
        "# mask_paths = sorted(list((DATASET_PATH/MASKS_DIR).glob(\"*\")), key=lambda p: p.stem)\n",
        "# print(\"[INFO] Found {} images and {} masks\".format(len(img_paths), len(mask_paths)))\n",
        "\n",
        "# imgs_df = pd.DataFrame(data={'file_path': img_paths})\n",
        "# masks_df = pd.DataFrame(data={'file_path': mask_paths})\n",
        "\n",
        "# imgs_df[\"tumor_type\"]  = [\"MASS\" if \"MASS\" in str(p) else \"CALC\" for p in imgs_df[\"file_path\"]]\n",
        "# masks_df[\"tumor_type\"] = [\"MASS\" if \"MASS\" in str(p) else \"CALC\" for p in masks_df[\"file_path\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOM0qvJ2EQ5E",
        "colab_type": "text"
      },
      "source": [
        "#### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo5GanditZpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed = 42\n",
        "# np.random.seed(seed)\n",
        "# total = len(imgs_df)\n",
        "# indices = np.arange(0, total)\n",
        "# np.random.shuffle(indices)\n",
        "\n",
        "# imgs_df['subset'] = ''\n",
        "# masks_df['subset'] = ''\n",
        "\n",
        "# start_idx = 0\n",
        "# for _subset in config['dataset']:\n",
        "#   print(_subset, config['dataset'][_subset])\n",
        "#   next_idx = int(config['dataset'][_subset] * total)\n",
        "#   print(next_idx)\n",
        "#   selected = indices[start_idx:next_idx]\n",
        "#   imgs_df.loc[imgs_df.index.isin(selected), 'subset'] = _subset\n",
        "#   masks_df.loc[masks_df.index.isin(selected), 'subset'] = _subset\n",
        "#   start_idx = next_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbhmNEd1H4EM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imgs_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pt7j8Q_rtZm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imgs_df.to_csv(IMGS_CSV, index=False)\n",
        "# masks_df.to_csv(MASKS_CSV, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKqulbBCNrVP",
        "colab_type": "text"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xu-VRn4X5mP",
        "colab_type": "text"
      },
      "source": [
        "#### Build the U-Net model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmKTXClytZzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unet = UNetModel()\n",
        "model = unet.build(width=config['target_size'][0],\n",
        "                  height=config['target_size'][1],\n",
        "                  n_channels=config['n_channels'],\n",
        "                  with_bn=True)\n",
        "# print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEnuKhDgYv6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def choose_optimizer(opt_name, opt_param):\n",
        "    if opt_name == 'rmsprop':\n",
        "        return optimizers.RMSprop(**opt_param)\n",
        "    elif opt_name == 'adam':\n",
        "        return optimizers.Adam(**opt_param)\n",
        "    elif opt_name == 'sgd':\n",
        "        return optimizers.SGD(**opt_param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iQU_3w3tZ1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = choose_optimizer(config['opt_name'], config['opt_param'])\n",
        "opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ2AC9titZ3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model.compile(optimizer=opt, loss=cm.dice_coef_loss, metrics=[cm.dice_coef])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skqgsNddZe4t",
        "colab_type": "text"
      },
      "source": [
        "#### Define callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hp3--e4ZuXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = []\n",
        "\n",
        "file_path = CHECKPOINTS_PATH/\"unet_weights-{epoch:002d}-{val_loss:.5f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks.append(checkpoint)\n",
        "\n",
        "# early_stopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=config[\"patience\"])\n",
        "# callbacks.append(early_stopping)\n",
        "\n",
        "csv_filename = TRAIN_PATH/\"history_{}.csv\".format(RUN_TIME)\n",
        "csv_logger = CSVLogger(csv_filename, separator=',', append=True)\n",
        "callbacks.append(csv_logger)\n",
        "print(\"[INFO] Added {} callbacks\".format(len(callbacks)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSmwv2bdeonj",
        "colab_type": "text"
      },
      "source": [
        "#### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUyFeZTwtZwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_shape = [config['batch_size'], config['target_size'][0], config['target_size'][1], config['n_channels']]\n",
        "mask_shape  = [config['batch_size'], config['target_size'][0], config['target_size'][1], 1]\n",
        "seed = 43\n",
        "\n",
        "train_generator = gen.image_mask_generator_imgaug(imgs_df,\n",
        "                                                  masks_df,\n",
        "                                                  subset=\"train\",\n",
        "                                                  batch_size=config['batch_size'],\n",
        "                                                  target_size=config['target_size'],\n",
        "                                                  data_aug=True,\n",
        "                                                  seed=seed)\n",
        "\n",
        "val_generator = gen.image_mask_generator_imgaug(imgs_df,\n",
        "                                                masks_df,\n",
        "                                                subset=\"val\",\n",
        "                                                batch_size=config['batch_size'],\n",
        "                                                target_size=config['target_size'],\n",
        "                                                data_aug=False,\n",
        "                                                seed=seed)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: map(tuple, train_generator), \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=(image_shape, mask_shape))\n",
        "print(\"[INFO] Train dataset: \", train_dataset)\n",
        "\n",
        "val_dataset   = tf.data.Dataset.from_generator(lambda: map(tuple, val_generator), \n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=(image_shape, mask_shape))\n",
        "print(\"[INFO] Validation dataset: \", val_dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrAReJ0oSoTq",
        "colab_type": "text"
      },
      "source": [
        "#### Vizualize a few training samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCz1fUGUa722",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples = list(train_dataset.take(4).as_numpy_iterator())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4O_Y50Oblgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(len(samples), 2, figsize=(10, 7))\n",
        "idx_img = 0 # image & mask index from each batch\n",
        "for idx, _sample in enumerate(samples):\n",
        "  batch_img, batch_mask = _sample\n",
        "  print(batch_img.shape, batch_mask.shape)\n",
        "  ax[idx][0].imshow(batch_img[idx_img])\n",
        "  ax[idx][0].axis('off')\n",
        "\n",
        "  mask_shape = batch_mask[idx_img].shape[:2]\n",
        "  conv_mask = np.zeros(shape=(mask_shape[0], mask_shape[1], 3), dtype=np.float32)\n",
        "  conv_mask[:, :, 0] = batch_mask[idx_img][:, :, 0]\n",
        "  conv_mask[:, :, 1] = batch_mask[idx_img][:, :, 0]\n",
        "  conv_mask[:, :, 2] = batch_mask[idx_img][:, :, 0]\n",
        "\n",
        "  ax[idx][1].imshow(conv_mask)\n",
        "  ax[idx][1].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4WWRa-yZuiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_nr_samples = len(imgs_df.loc[imgs_df['subset'] == \"train\", :])\n",
        "val_nr_samples   = len(imgs_df.loc[imgs_df['subset'] == \"val\", :])\n",
        "\n",
        "steps_per_epoch = np.ceil(train_nr_samples / config[\"batch_size\"])\n",
        "validation_steps = val_nr_samples // config[\"batch_size\"]\n",
        "\n",
        "print(\"[INFO] Train size {} Val size {}\".format(train_nr_samples, val_nr_samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADMG0sDpZdf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"[INFO] Starting training for {} epochs with batch size {}\".format(config['epochs'], config['batch_size']))\n",
        "model.fit(train_generator,\n",
        "          epochs=config[\"epochs\"],\n",
        "          validation_data=val_generator,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_steps=validation_steps,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsXzxIXxZdkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}